---
title: "Data Science Internship - Aliaksandr Samushchyk"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

!!!NOTE!!! Conclusions are based on my results. When you run the program it may give slightly different results due to the randomness incorporated in train/test sets and glmnet functions.

Reading data and cheching for nan and inf values

```{r}
data = read.csv('insurance.csv', header = T)
apply(data, 2, function(x) any(is.na(x) | is.infinite(x)))
```


checking levels of categorical variables and children variable

```{r}
levels(data$sex)
unique(data$children)
levels(data$region)
levels(data$smoker)
```

We can see from the boxplots below that smokers have higher charges than non smokers. It is difficult to assess visually influece of other categorical variables on charges. 

```{r}
library(ggplot2)
# Basic box plot
par(mfrow=c(2,2))
ggplot(data = data, aes(x=sex, y=charges))+geom_boxplot()
ggplot(data = data, aes(x=region, y=charges))+geom_boxplot()
ggplot(data = data, aes(x=smoker, y=charges))+geom_boxplot()
```

```{r}
par(mfrow=c(1,2))
ggplot(data = data, aes(x=age, y=charges))+geom_point()
ggplot(data = data, aes(x=bmi, y=charges))+geom_point()
```

```{r}
par(mfrow=c(1,2))
hist(data$age)
hist(data$bmi)
```

bmi variable looks normal, but we are unable to say the same about age variable. 


```{r}
hist(data$charges)
```

The distribution of charges does not look like normal which may cause some issues in future. It could be the case that we will need to consider some transformation of charges variable.

Below is the code for creation of some additional variable creation to possibly improve the fit. The variables created: squared age, squared bmi. Additionally, children variable were transformed into categorical variable child_factor where 0 means an individual has 0 children, >=3 means an individual has 3 or more children. Old Variable Children is moved out of the dataset.

```{r}
data$child_factor = cut(data$children, br = c(-1,0,1,2,5), labels = c("0", "1","2",">=3"))
data$age_sq = data$age^2
data$bmi_sq = data$bmi^2
data1 = data[,c(1,2,3,5,6,7,8,9,10)]
```


Now we randomly split our dataset into train and test sets in proportion 80/20. 

```{r}
set.seed(124523)
n = round(nrow(data1)*0.8)
train_index = sample.int(nrow(data1),n)
test_index = setdiff(seq(1,nrow(data1)),train_index)
train = data1[train_index,]
test = data1[test_index,]
```

Building the initial full model(using all variables) on non-transformed charges.

```{r}
#building full model on train data
full_model = lm(charges~., data = train)
summary(full_model)
```

We got pretty good value of the coefficient of determination and of the adjusted R squared. We need to perform model diagnostics(residual analysis) in order to assess if the model is a good fit.

```{r}
plot(full_model)
```


Checking assumptions:
On the plots above we can notice that the homoscedasticity, normality and linearity assumptions are violated. We can inspect it visually, thus there is no need in numerical tests. One way of addressing poor fit is to consider transformation of the dependent variable in order to try to satisfy these assumptions. We will try box-cox transformation method.

```{r}
library(MASS)
bc = boxcox(full_model, lambda = seq(-3,3))
```

The best suggested transformation of the response variable suggested by Box-Cox approach is lambda close to zero, thus we will apply lambda=0 transformation(which is log of response variable).

```{r}
log_full_model = lm(log(charges)~., data = train)
summary(log_full_model)
```

Cheching the assumptions of the model.

```{r}
plot(log_full_model)
```

Still our assumptions of linear regression are not satisfied(homoscedasticity, normality, linearity). Note that R^2^ and adjusted R^2^ slightly increased comparing to the previous(non-transformed model).
Let's take a closer look at cook's distances of our model.

```{r}
#cooks.distance(log_full_model)
points_to_remove = which(cooks.distance(log_full_model)>1)
print(which(cooks.distance(log_full_model)>1))
```

There are no infuential points detected by cook's distance approach. I use pretty generous threshold for cook's distance to be considered as large(i.e. 1). When considering more strict well known thresholds such as 4/N or 4/(N-k-1) there are a lot of observations detected as inflential so I stopped my choice at 1.

We see that our model is not a good fit since it violates the assumption of OLS model. We will assess its predicting abilities in the end of this file comparing it to the other models built later.

Now we will try different methods(Stepwise regression, Elastic Net, Ridge Regression and Lasso model). We will use these methods on log-transformed charges variable since it's dignostic plots seem slightly more plausible than those after full non-transformed model.

```{r}
#Forward Stepwise regression

minimum = lm(log(charges)~1,data = train)

# Forward
forward.model = step(minimum, scope = list(lower=minimum, upper = log_full_model), direction = "forward")
summary(forward.model)
```

Forward Stepwise regression showed that the best model in terms of AIC is the full nodel. It can also be noticed that the most important variables(i.e. those forward stepwide approach selected as first candidates entering the regression model) are smoker, age and newly created factor variable as child_factor.

```{r}
#Stepwise regression with both directions
both.full.model =step(log_full_model, scope = list(lower=minimum, upper = log_full_model), direction = "both")
summary(both.full.model)
```

The result of Forward Stepwise regression is supported by Stepwise regression with both directions.


Now we build other models.
First, we create predictors matrix and response vector.


```{r}
library(glmnet)
predictors = as.matrix(train[,c(1,3,8,9)])

child_0 = as.numeric(train$child_factor=='0')
child_1 = as.numeric(train$child_factor=='1')
child_2 = as.numeric(train$child_factor=='2')
child_3 = as.numeric(train$child_factor=='>=3')

sex_male = as.numeric(train$sex=='male')
sex_female = as.numeric(train$sex=='female')

smoker_yes = as.numeric(train$smoker=='yes')
smoker_no = as.numeric(train$smoker=='no')

region_northeast = as.numeric(train$region=='northeast')
region_northwest = as.numeric(train$region=='northwest')
region_southwest = as.numeric(train$region=='southwest')
region_southeast = as.numeric(train$region=='southeast')

predictors = cbind(predictors,child_1,child_2,child_3,smoker_yes,sex_male,region_northwest,region_southwest,region_southeast)

charges = train$charges
```


Now, we fit Lasso Regression

```{r}
## Lasso Regression
# Find the optimal lambda using 10-fold CV 
lassomodel.cv=cv.glmnet(predictors,log(charges),alpha=1,nfolds=10)
## Fit lasso model with 100 values for lambda
lassomodel = glmnet(predictors,log(charges), alpha = 1, nlambda = 100)
## Plot coefficient paths
plot(lassomodel,xvar="lambda",lwd=2,label=TRUE)
abline(v=log(lassomodel.cv$lambda.min),col='black',lty = 2,lwd=2)
## Extract coefficients at optimal lambda
coef(lassomodel,s=lassomodel.cv$lambda.min)
```




We can see from above results that the variables selected by the LASSO regression are all the same as in the full model(at the optimal value of lambda, i.e. such lambda that gives the minimum mean cross-validated error). No coefficients are set to zero in LASSO regression result.

Below is the fitting of Ridge and Elastic Net Regressions.

```{r}
#Ridge Regression
# Optimize lambda using cross validation
cv.ridge = cv.glmnet(predictors, log(charges), alpha=0)
#print coefs corresponding to the optimized lambda
coef(cv.ridge,s=cv.ridge$lambda.min)
```




```{r}
## Elastic Net Regression with alpha = 0.5
# Find the optimal lambda using 10-fold CV  
enetmodel.cv=cv.glmnet(predictors,log(charges),alpha=0.5,nfolds=10)
## Fit lasso model with 100 values for lambda
enetmodel = glmnet(predictors,log(charges), alpha = 0.5, nlambda = 100)
## Plot coefficient paths
plot(enetmodel,xvar="lambda",label=T, lwd=2)
abline(v=log(enetmodel.cv$lambda.min),col='black',lty = 2,lwd=2)
## Extract coefficients at optimal lambda
coef(enetmodel,s=enetmodel.cv$lambda.min)
```

The variables present in Elastic Net model(with alpha 0.5) are all the same as in the full model except for newly created age_sq and bmi_sq.


Model comparison on the Test Data:

First, we create the predictor and response test data matrices.

```{r}
predictors_test = as.matrix(test[,c(1,3,8,9)])

child_0_test = as.numeric(test$child_factor=='0')
child_1_test = as.numeric(test$child_factor=='1')
child_2_test = as.numeric(test$child_factor=='2')
child_3_test = as.numeric(test$child_factor=='>=3')

sex_male_test = as.numeric(test$sex=='male')
sex_female_test = as.numeric(test$sex=='female')

smoker_yes_test = as.numeric(test$smoker=='yes')
smoker_no_test = as.numeric(test$smoker=='no')

region_northeast_test = as.numeric(test$region=='northeast')
region_northwest_test = as.numeric(test$region=='northwest')
region_southwest_test = as.numeric(test$region=='southwest')
region_southeast_test = as.numeric(test$region=='southeast')

predictors_test = cbind(predictors_test,child_1_test,child_2_test,child_3_test,smoker_yes_test,sex_male_test,region_northwest_test,region_southwest_test,region_southeast_test)

charges_test = test$charges
```


Calculating of the predictions of the log charges based on the four models.

```{r}
full_predict = predict(log_full_model, test)
ridge_predict = as.vector(predict(cv.ridge, predictors_test,s=cv.ridge$lambda.min))
lasso_predict = as.vector(predict(lassomodel,predictors_test,s=lassomodel.cv$lambda.min))
enet_predict = as.vector(predict(enetmodel,predictors_test,s=enetmodel.cv$lambda.min))
```


I decided to use MAPE as the perfomance measure of the models. It allows to compare the results of the models on the test set.
MAPE(Mean Absolute Prcentage error calculation for all models) - 

```{r}
cat("MAPE for full model:", mean(abs((full_predict-log(charges_test))/log(charges_test))))
cat("\nMAPE for ridge model:", mean(abs((ridge_predict-log(charges_test))/log(charges_test))))
cat("\nMAPE for lasso model:", mean(abs((lasso_predict-log(charges_test))/log(charges_test))))
cat("\nMAPE for el net model:", mean(abs((enet_predict-log(charges_test))/log(charges_test))))
```

Elastic Net model has the lowest MAPE and also it has the lowest number of predictors inside. Let's now assess MAPE results on original scale of charges. Thus, we turn our prediction into exponential function.


```{r}
exp_full_predict = exp(full_predict)
exp_ridge_predict = exp(ridge_predict) 
exp_lasso_predict = exp(lasso_predict)
exp_enet_predict = exp(enet_predict)
cat("MAPE for full model:", mean(abs((exp_full_predict-charges_test)/charges_test)))
cat("\nMAPE for ridge model:", mean(abs((exp_ridge_predict-charges_test)/charges_test)))
cat("\nMAPE for lasso model:", mean(abs((exp_lasso_predict-charges_test)/charges_test)))
cat("\nMAPE for el net model:", mean(abs((exp_enet_predict-charges_test)/charges_test)))
```

This time, LASSO model shows the best result.(lowest MAPE)

To be consistent, I also build the models using non-transformed charges variable.


```{r}
## Lasso Regression
# Find the optimal lambda using 10-fold CV 
lassomodel1.cv=cv.glmnet(predictors,charges,alpha=1,nfolds=10)
## Fit lasso model with 100 values for lambda
lassomodel1 = glmnet(predictors,charges, alpha = 1, nlambda = 100)
## Plot coefficient paths
plot(lassomodel1,xvar="lambda",lwd=2,label=TRUE)
abline(v=log(lassomodel1.cv$lambda.min),col='black',lty = 2,lwd=2)
## Extract coefficients at optimal lambda
coef(lassomodel1,s=lassomodel1.cv$lambda.min)
```




```{r}
#Ridge Regression
# Optimize lambda using cross validation
cv.ridge1 = cv.glmnet(predictors, charges, alpha=0)
#print coefs corresponding to the optimized lambda
coef(cv.ridge1,s=cv.ridge1$lambda.min)
```



```{r}
## Elastic Net Regression with alpha = 0.5
# Find the optimal lambda using 10-fold CV  
enetmodel1.cv=cv.glmnet(predictors,charges,alpha=0.5,nfolds=10)
## Fit lasso model with 100 values for lambda
enetmodel1 = glmnet(predictors,charges, alpha = 0.5, nlambda = 100)
## Plot coefficient paths
plot(enetmodel1,xvar="lambda",label=T, lwd=2)
abline(v=log(enetmodel1.cv$lambda.min),col='black',lty = 2,lwd=2)
## Extract coefficients at optimal lambda
coef(enetmodel1,s=enetmodel1.cv$lambda.min)
```


```{r}
full_predict1 = predict(full_model, test)
ridge_predict1 = as.vector(predict(cv.ridge1, predictors_test,s=cv.ridge1$lambda.min))
lasso_predict1 = as.vector(predict(lassomodel1,predictors_test,s=lassomodel1.cv$lambda.min))
enet_predict1 = as.vector(predict(enetmodel1,predictors_test,s=enetmodel1.cv$lambda.min))
cat("MAPE for full model(non-transformed):", mean(abs((full_predict1-charges_test)/charges_test)))
cat("\nMAPE for ridge model(non-transformed):", mean(abs((ridge_predict1-charges_test)/charges_test)))
cat("\nMAPE for lasso model(non-transformed):", mean(abs((lasso_predict1-charges_test)/charges_test)))
cat("\nMAPE for el net model(non-transformed):", mean(abs((enet_predict1-charges_test)/charges_test)))
```

MAPE for these models are way worse than those of the models with transformed charges.

To be fully sure in choosing the model I also calculate the MSE for all 4 models.

```{r}
ss_total = sum((charges_test-mean(charges_test))^2)
ss_reg_full = mean((exp_full_predict-charges_test)^2)
ss_reg_ridge = sum((exp_ridge_predict-mean(charges_test))^2)
ss_reg_lasso = sum((exp_lasso_predict-mean(charges_test))^2)
ss_reg_enet = sum((exp_enet_predict-mean(charges_test))^2)

cat("MSE for test data, full model:", mean((exp_full_predict-charges_test)^2))
cat("\nMSE squared for test data, ridge model:", mean((exp_ridge_predict-charges_test)^2))
cat("\nMSE squared for test data, lasso model:", mean((exp_lasso_predict-charges_test)^2))
cat("\nMSE squared for test data, el net model:", mean((exp_enet_predict-charges_test)^2))
```

If to consider MSE metric, the ridge regression is the one with lowest MSE.
 
NOTE! Conclusions are based on my results. When you run the program it may give slightly different results due to the randomness incorporated in train/test sets and glmnet functions.

In conclusion, the full models(both with transformed and non-transformed charges) were not a good fit, the model diagnostics showed that the assumptions are violated. They do not have a good statistical fit. After considering all the 4 models on transformed charges, my suggestion is to use the full model for predictions(with transformed charges). It has the second best result in both MSE and MAPE metrics. Though it is not a good statistical fit its predicting abilities are okay. MAPE of the full model is equal to 0.2750435 which means that on average, the prediction errro is equal ~27% of the actual value.

Top 3 most important factors(factors with the highest impact) identified by forward stepwise regression:
1) smoker
2) age
3) child_factor

The chosen full model on the whole data and its summary are presented below.

```{r}
chosen_model = lm(log(charges)~., data = data1)
summary(chosen_model)
```

All variables are significant at 5% level. Our model explains ~77% of the variability in log(charges) variable.

